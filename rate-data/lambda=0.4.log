2023-04-15 17:05:23,680 - cli.py - This is Paynt version 0.1.0.
2023-04-15 17:05:23,680 - sketch.py - loading sketch from ./models/pomdp/no-goal-state/blind-nanny/sketch.templ ...
2023-04-15 17:05:23,682 - prism_parser.py - PRISM model type: PrismModelType.POMDP
2023-04-15 17:05:23,682 - prism_parser.py - loading properties from ./models/pomdp/no-goal-state/blind-nanny/sketch.props ...
2023-04-15 17:05:23,683 - prism_parser.py - found the following specification: constraints: LRA>3/5 ["goal1"],LRA>3/5 ["goal2"], optimality objective: none
2023-04-15 17:05:23,702 - sketch.py - constructed explicit quotient having 27 states and 90 actions
2023-04-15 17:05:23,702 - sketch.py - found the following specification constraints: LRA>3/5 ["goal1"],LRA>3/5 ["goal2"], optimality objective: none
2023-04-15 17:05:23,703 - quotient_pomdp.py - Constructed POMDP having 15 observations.
2023-04-15 17:05:23,703 - quotient_pomdp.py - Unfolding POMDP using the following memory allocation vector: [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1] ...
2023-04-15 17:05:23,703 - quotient_pomdp.py - Constructed quotient MDP having 27 states and 90 actions.
2023-04-15 17:05:23,703 - synthesizer.py - Synthesis initiated.
> Progress 12.611%, elapsed 3.0 s, iters = (2691, 0), opt = -
> Progress 50.5396%, elapsed 6.0 s, iters = (8105, 0), opt = -

--------------------
Synthesis summary
constraint 1: LRA>3/5 ["goal1"]
constraint 2: LRA>3/5 ["goal2"]

method: AR, synthesis time: 7.4 s
number of holes: 12, family size: 16777216, super quotient: 27 states / 90 actions
explored: 100 %
AR stats: avg MDP size: 20, iterations: 11066

feasible: no
--------------------

